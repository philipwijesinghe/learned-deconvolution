
# Learned deconvolution using physics priors

This repository contains code for learned deconvolution using physics priors for structured light-sheet microscopy.

This work was first presented in:

*Wijesinghe P., Corsetti S., Chow D.J.X., Sakata S., Dunning K.R., Dholakia K.* 
**Learned deconvolution using physics priors for structured light-sheet microscopy** 
(PREPRINT) 2021



## Description

This code (PyTorch) trains a deep convolutional neural network (based on GANs) that is able to perform deconvolution and super-resolution of microscopy data that is encoded by structured light fields (i.e., a structured point-spread function), such as the Airy and Bessel beams.
The network uses simulated paired images based on the known physics of light propagation.
It further uses unpaired real images for saliency.

This code is separated into several functionalities.
- Simulation of paired images using the principles of image formation in light-sheet microscopy (LSM)
- Network training using simulated and real LSM data
- Inference of image sequences



### Acknowledgements

We acknowledge Erik Linder-Noren's [implementations of GANs in PyTorch](https://github.com/eriklindernoren/PyTorch-GAN) that instantiated the code developed in this project.



## Workflow


### Simulate image pairs

To create simulated physics image pairs, the user manually creates a folder containing a ```PhysicsDataConfig.yml``` configuration file which lists all parameters and instructions to generate the data.
A template is available in the ```config_templates``` folder.
Data is generated by running ```prepare_physics_data.py``` with the folder path as a variable.


### Train network

To train the network, the user manually creates a folder containing a ```TrainConfig.yml``` configuration file which lists all training parameters. 
A template is available in the ```config_templates``` folder.
The configuration file must also include at least one path to simulated image pairs and at least one path to a folder containing real microscopy images. 
Real images must be 64x64 pixel PNG images.
Network training is initialised using ```train_physics_model.py```, and will populate the folder with training images to visualise training progress, and will periodically save the model in the ```/saved_model``` subfolder.

Network training without real microscopy images can be performed using ```train_simulation_model.py```.


### Inference

Widefield microscopy images can be processed using a trained network.
Widefield images can be a sequence of PNG images of any size.
This is done by running ```process_trained_batch.py``` with the directories of the widefield image sequence and also the associated path to the trained network ```/saved_model``` subfolder.



## Data and Demo

Data underpinning the publication is available at [https://doi.org/10.17630/bf92bc18-0b81-41f7-bd44-d74040af7cf0](https://doi.org/10.17630/bf92bc18-0b81-41f7-bd44-d74040af7cf0).

This data includes a demo dataset that illustrates the functionality of this code and the expected structure of the outputs.
The instructions to run the demo using the code included in this repository is included in the parent folder of the data.
The demo should take several hours to train, depending on the GPU. (2.5 hours on NVidia RTX 2060), and several seconds for inference.

### Reproduction

We note that perfect reproduction of trained models even with the same training data is not feasible.
This is because network training is stochastic and rarely deterministic. 
However, the inference of LSM image data with the included trained models will reproduce the outputs, which are also included.
Further, models trained with identical images and hyperparameters should exhibit equivalent performance to the included pre-trained models.



## Folder listings

```beams\```

Code to generate Gaussian, Airy and Bessel beam shapes


```config_templates\```

Templates of configuration files used for image pair simulation and network training


```deeplearn\```

Code to perform deep learning using PyTorch


```fileio\```

Supporting functions for reading and writing files


```lsm\```

Code to simulate LSM images and PSFs



## System requirements and installation

(Installation of all packages may take several hours.)

Deep learning uses **PyTorch**.
We have tested our code on Windows 10 and python 3.9 using the Anaconda environment.

Here, Anaconda was installed and included in the Windows 10 PATH.
We can create a fresh Anacoda (python 3.9) environment (called 'DD' for Deep Deconvolution) using the command prompt.

```
conda create --name DD python=3.9
```
```
conda activate DD
```

PyTorch makes use of NVidia GPUs via the CUDA Toolkit [https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit), which must be installed if a GPU is to be used for training or inference.

PyTorch can be installed following the instructions on [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/).

For example by running:
```
conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c conda-forge
```

We make use of additional libraries:

```
conda install matplotlib scipy pyyaml
```

This should provide the necessary environment for PyTorch with CUDA.

In python, the GPU Test should return ```true``` if using a compatible graphics card.

```python
import torch
torch.cuda.is_available()
```


### Package Version

The full package listing, including the version information, is included in ```env.md```




